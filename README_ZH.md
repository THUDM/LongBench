![](misc/logo.gif)
<p align="center">
    ğŸ¤— <a href="https://huggingface.co/datasets/THUDM/LongBench" target="_blank">HF Repo</a> â€¢ ğŸ“ƒ <a href="https://arxiv.org/abs/2308.14508" target="_blank">Paper</a>
</p>

Read this in [English](README.md).

# ğŸ“– LongBench: å¤šä»»åŠ¡ä¸­è‹±åŒè¯­é•¿æ–‡æœ¬ç†è§£è¯„æµ‹åŸºå‡†

**LongBench**æ˜¯ç¬¬ä¸€ä¸ªå¤šä»»åŠ¡ã€ä¸­è‹±åŒè¯­ã€é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹**é•¿æ–‡æœ¬ç†è§£èƒ½åŠ›**çš„è¯„æµ‹åŸºå‡†ã€‚åœ¨ç›®å‰å¤§æ¨¡å‹å¤šè¯­è¨€èƒ½åŠ›å¼•èµ·å¹¿æ³›å…³æ³¨çš„èƒŒæ™¯ä¸‹ï¼ŒLongBenchæ¶µç›–äº†ä¸åŒçš„è¯­è¨€ï¼ˆä¸­æ–‡å’Œè‹±æ–‡ï¼‰ï¼Œä»¥æ­¤æ¥å¯¹å¤§æ¨¡å‹åœ¨é•¿æ–‡æœ¬ä¸‹çš„å¤šè¯­è¨€èƒ½åŠ›è¿›è¡Œæ›´å…¨é¢çš„è¯„ä¼°ã€‚åŒæ—¶ï¼ŒLongBenchç”±å…­å¤§ç±»ã€äºŒåä¸€ä¸ªä¸åŒçš„ä»»åŠ¡ç»„æˆï¼Œè¦†ç›–äº†å•æ–‡æ¡£QAã€å¤šæ–‡æ¡£QAã€æ‘˜è¦ã€Few-shotå­¦ä¹ ã€åˆæˆä»»åŠ¡å’Œä»£ç è¡¥å…¨ç­‰å…³é”®çš„é•¿æ–‡æœ¬åº”ç”¨åœºæ™¯ã€‚

æˆ‘ä»¬æ·±çŸ¥æ¨¡å‹è¯„æµ‹è¿‡ç¨‹ä¸­å¯èƒ½äº§ç”Ÿçš„é«˜æ˜‚æˆæœ¬ï¼Œå°¤å…¶æ˜¯é•¿æ–‡æœ¬åœºæ™¯ä¸‹ï¼ˆå¦‚äººå·¥æ ‡æ³¨æˆæœ¬æˆ–APIè°ƒç”¨æˆæœ¬ï¼‰ã€‚å› æ­¤ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§å…¨è‡ªåŠ¨çš„è¯„æµ‹æ–¹å¼ï¼Œæ—¨åœ¨ä»¥æœ€ä½çš„æˆæœ¬ï¼Œæœ€æœ‰æ•ˆåœ°è¡¡é‡å’Œè¯„ä¼°æ¨¡å‹çš„é•¿æ–‡æœ¬ç†è§£èƒ½åŠ›ã€‚

LongBenchåŒ…å«14ä¸ªè‹±æ–‡ä»»åŠ¡ã€5ä¸ªä¸­æ–‡ä»»åŠ¡å’Œ2ä¸ªä»£ç ä»»åŠ¡ï¼Œå¤šæ•°ä»»åŠ¡çš„å¹³å‡é•¿åº¦åœ¨5k-15kä¹‹é—´ï¼Œå…±åŒ…å«4750æ¡æµ‹è¯•æ•°æ®ã€‚å…³äºLongBenchæ•°æ®é›†çš„å…·ä½“ç»Ÿè®¡åŠä»»åŠ¡æ„é€ æ–¹å¼è¯·å‚è€ƒ[è¿™é‡Œ](task_zh.md)ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜é€šè¿‡å‡åŒ€é‡‡æ ·å¾—åˆ°äº†é•¿åº¦åˆ†å¸ƒæ›´å‡åŒ€çš„æµ‹è¯•é›†åˆLongBench-Eï¼Œåœ¨0-4kã€4k-8kã€8k+é•¿åº¦åŒºé—´å†…çš„æ•°æ®é‡ç›¸å½“ï¼Œä»¥æä¾›æ¨¡å‹åœ¨ä¸åŒé•¿åº¦ä¸‹æ€§èƒ½å˜åŒ–çš„åˆ†æã€‚

![](misc/overview.png)
|   ä»»åŠ¡ç±»å‹   | è‹±æ–‡ä»»åŠ¡æ•° | ä¸­æ–‡ä»»åŠ¡æ•° | ä»£ç ä»»åŠ¡æ•° |
| :----------: | :--------: | :--------: | :--------: |
|   å•æ–‡æ¡£QA   |     3      |     1      |     -      |
|   å¤šæ–‡æ¡£QA   |     3      |     1      |     -      |
|     æ‘˜è¦     |     3      |     1      |     -      |
| Few-shotå­¦ä¹  |     3      |     1      |     -      |
|   åˆæˆä»»åŠ¡   |     2      |     1      |     -      |
|   ä»£ç è¡¥å…¨   |     -      |     -      |     2      |

## ğŸ”¥ æ›´æ–°ä¿¡æ¯
**[2023/08/29]** [LongBenchè®ºæ–‡](https://arxiv.org/abs/2308.14508)å‘å¸ƒï¼ŒåŒæ—¶å¯¹LongBenchè¿›è¡Œäº†ä»¥ä¸‹å‡ é¡¹é‡è¦æ›´æ–°ï¼š
1. **æ›´å…¨é¢çš„æ•°æ®é›†**ï¼šåœ¨æ‘˜è¦ä»»åŠ¡ä¸­å¢åŠ äº†å¤šæ–‡æ¡£æ‘˜è¦MultiNewsæ•°æ®é›†ï¼Œåœ¨Few-shotå­¦ä¹ ä»»åŠ¡ä¸­å¢åŠ äº†æ‘˜è¦ä»»åŠ¡SAMSumï¼Œä»£æ›¿ä¹‹å‰çš„QAä»»åŠ¡NQï¼Œå¹¶å¯¹TriviaQA, RepoBench-Pè¿›è¡Œé‡æ–°é‡‡æ ·ä»¥ä¿è¯æ•°æ®é•¿åº¦æ›´åŠ åˆé€‚ï¼›
2. **æ›´å‡åŒ€çš„é•¿åº¦åˆ†å¸ƒ**ï¼šæ ¹æ®é•¿åº¦è¿›è¡Œå‡åŒ€é‡‡æ ·å¾—åˆ°äº†LongBench-Eï¼Œå…¶åŒ…å«LongBenchä¸­çš„13ä¸ªé•¿åº¦åˆ†å¸ƒæ›´åŠ å‡åŒ€çš„è‹±æ–‡æ•°æ®é›†ï¼ŒLongBench-Eåœ¨0-4kï¼Œ4-8kï¼Œ8k+é•¿åº¦åŒºé—´å†…å‡æœ‰æ•°é‡ç›¸å½“çš„æµ‹è¯•æ•°æ®ï¼Œæ›´åŠ é€‚åˆè¯„ä»·æ¨¡å‹åœ¨ä¸åŒè¾“å…¥é•¿åº¦ä¸Šçš„èƒ½åŠ›å˜åŒ–ï¼›
3. **å…¨éƒ¨è¯„æµ‹ä»£ç å…¬å¼€**ï¼šè¯„æµ‹æ‰€æœ‰æ¨¡å‹çš„ä»£ç å·²å…¬å¼€ï¼ŒåŒæ—¶æä¾›äº†åŸºäºæ£€ç´¢ã€åˆ†æ®µæ‘˜è¦çš„é•¿æ–‡æœ¬å‹ç¼©ç­–ç•¥ä»£ç ã€‚

## ğŸ” ç›®å½•
- [ğŸ–¥ï¸ æ’è¡Œæ¦œ](#æ’è¡Œæ¦œ)
- [âš™ï¸ å¦‚ä½•åœ¨LongBenchä¸Šè¯„æµ‹æ¨¡å‹](#å¦‚ä½•åœ¨LongBenchä¸Šè¯„æµ‹æ¨¡å‹)
- [ğŸ“Š è¯¦ç»†è¯„æµ‹ç»“æœ](#è¯¦ç»†è¯„æµ‹ç»“æœ)
- [ğŸ“„ è‡´è°¢](#è‡´è°¢)
- [ğŸ“ å¼•ç”¨](#å¼•ç”¨)

<a name="æ’è¡Œæ¦œ"></a>
## ğŸ–¥ï¸ æ’è¡Œæ¦œ
æˆ‘ä»¬åœ¨è¿™é‡Œå±•ç¤ºäº†æ‰€æœ‰æ¨¡å‹åœ¨Zero-shotåœºæ™¯ä¸‹ï¼Œåœ¨ä¸­æ–‡å’Œè‹±æ–‡å„å¤§ç±»ä»»åŠ¡ä¸Šå¾—åˆ†çš„å¹³å‡å€¼ï¼ˆ%ï¼‰ï¼Œå„ä»»åŠ¡è¯„ä¼°æ‰€ç”¨æŒ‡æ ‡è¯·å‚è€ƒ[è¿™é‡Œ](task_zh.md)ã€‚

> æ³¨ï¼šå¯¹äºè¶…å‡ºæ¨¡å‹å¤„ç†é•¿åº¦èƒ½åŠ›çš„æ–‡æœ¬ï¼Œå‚è€ƒ[Lost in the Middle](https://arxiv.org/abs/2307.03172)çš„è§‚å¯Ÿï¼Œæˆ‘ä»¬ä»æ–‡æœ¬ä¸­é—´è¿›è¡Œæˆªæ–­ï¼Œä¿æŒå‰åéƒ¨åˆ†çš„ä¿¡æ¯ã€‚å®éªŒè¡¨æ˜ï¼Œè¿™ç§æˆªæ–­æ–¹å¼å¯¹æ¨¡å‹æ€§èƒ½å½±å“æœ€å°ã€‚

#### è‹±æ–‡æ¦œå•
|     | Avg | å•æ–‡æ¡£QA | å¤šæ–‡æ¡£QA | æ‘˜è¦ | Few-shotå­¦ä¹  | ä»£ç è¡¥å…¨ | åˆæˆä»»åŠ¡ |
| --- | :-: | :-: | :-: | :-: | :-: | :-: | :-: |
| GPT-3.5-Turbo-16k | 44.0 | 39.8 | 38.7 | 26.5 | 67.1 | 54.1 | 37.8 |
| Llama2-7B-chat-4k | 31.0 | 24.9 | 22.6 | 24.7 | 60.0 | 48.1 | 5.9 |
| LongChat-v1.5-7B-32k | 34.3 | 28.7 | 20.6 | 26.7 | 60.0 | 54.1 | 15.8 |
| XGen-7B-8k | 28.3 | 24.6 | 20.4 | 24.7 | 56.2 | 38.6 | 5.3 |
| InternLM-7B-8k | 24.2 | 17.4 | 20.2 | 16.1 | 50.3 | 36.4 | 4.5 |
| ChatGLM2-6B | 26.6 | 23.1 | 16.2 | 23.2 | 48.2 | 46.1 | 2.8 |
| ChatGLM2-6B-32k | 40.9 | 32.9 | 33.7 | 27.6 | 59.1 | 52.7 | 39.2 |
| Vicuna-v1.5-7B-16k | 31.9 | 28.0 | 18.6 | 26.0 | 66.2 | 47.3 | 5.5 |

#### ä¸­æ–‡æ¦œå•
|       | Avg | å•æ–‡æ¡£QA | å¤šæ–‡æ¡£QA | æ‘˜è¦ | Few-shotå­¦ä¹  | ä»£ç è¡¥å…¨ | åˆæˆä»»åŠ¡ |
|-------|:---:|:-------------:|:------------:|:-------------:|:-----------------:|:---------------:|:----------------:|
| GPT-3.5-Turbo-16k | 44.5 | 61.2 | 28.7 | 16.0 | 29.2 | 54.1 | 77.5 |
| Llama2-7B-chat-4k | 14.3 | 11.9 | 5.2 | 0.2 | 19.8 | 48.1 | 0.5 |
| LongChat-v1.5-7B-32k | 23.9 | 29.1 | 19.5 | 9.9 | 23.2 | 54.1 | 7.6 |
| XGen-7B-8k | 15.1 | 14.8 | 11.0 | 2.2 | 20.5 | 38.6 | 3.5 |
| InternLM-7B-8k | 18.3 | 33.6 | 11.1 | 12.4 | 15.2 | 36.4 | 0.9 |
| ChatGLM2-6B | 22.9 | 33.2 | 16.3 | 14.5 | 20.8 | 46.1 | 6.5 |
| ChatGLM2-6B-32k | 41.7 | 51.6 | 37.6 | 16.2 | 27.7 | 52.7 | 64.5 |
| Vicuna-v1.5-7B-16k | 26.4 | 43.0 | 19.3 | 15.1 | 28.8 | 47.3 | 5.0 |

#### é•¿æ–‡æœ¬ä»»åŠ¡èƒ½åŠ›é›·è¾¾å›¾
![](misc/radar.png)

#### ä¸åŒé•¿åº¦æ–‡æœ¬ä¸‹çš„èƒ½åŠ›å˜åŒ–
ä¸ºäº†æ›´æœ‰é’ˆå¯¹æ€§åœ°åˆ†ææ¨¡å‹åœ¨ä¸åŒæ–‡æœ¬é•¿åº¦ä¸‹çš„è¡¨ç°ï¼Œä¸‹å›¾å±•ç¤ºäº†æ¨¡å‹åœ¨LongBench-Eä¸­ä¸åŒæ–‡æœ¬é•¿åº¦åŒºé—´ä¸Šï¼Œæ‰€æœ‰ä»»åŠ¡ä¸ŠæŒ‰ç…§ä»»åŠ¡ç±»åˆ«è¿›è¡Œå¹³å‡çš„æ€»åˆ†ã€‚

![](misc/curve.png)

<a name="å¦‚ä½•åœ¨LongBenchä¸Šè¯„æµ‹æ¨¡å‹"></a>
## âš™ï¸ å¦‚ä½•åœ¨LongBenchä¸Šè¯„æµ‹æ¨¡å‹

#### è½½å…¥æ•°æ®
ä½ å¯ä»¥é€šè¿‡Hugging Face datasetsæ¥ä¸‹è½½å¹¶è½½å…¥**LongBench**çš„æ•°æ®ï¼ˆ[ğŸ¤— HF Repo](https://huggingface.co/datasets/THUDM/LongBench)ï¼‰:
```python
from datasets import load_dataset

datasets = ["narrativeqa", "qasper", "multifieldqa_en", "multifieldqa_zh", "hotpotqa", "2wikimqa", "musique", \
            "dureader", "gov_report", "qmsum", "multi_news", "vcsum", "trec", "triviaqa", "samsum", "lsht", \
            "passage_count", "passage_retrieval_en", "passage_retrieval_zh", "lcc", "repobench-p"]

for dataset in datasets:
    data = load_dataset('THUDM/LongBench', dataset, split='test')
```
ç±»ä¼¼åœ°ï¼Œä¹Ÿå¯ä»¥è½½å…¥**LongBench-E**çš„æ•°æ®
```python
from datasets import load_dataset

datasets = ["qasper", "multifieldqa_en", "hotpotqa", "2wikimqa", "gov_report", "multi_news", "trec", \
            "triviaqa", "samsum", "passage_count", "passage_retrieval_en", "lcc", "repobench-p"]

for dataset in datasets:
    data = load_dataset('THUDM/LongBench', f"{dataset}_e", split='test')
```
åŒæ ·åœ°ï¼Œä½ ä¹Ÿå¯ä»¥ç›´æ¥ç”¨è¿™ä¸ª[é“¾æ¥](https://huggingface.co/datasets/THUDM/LongBench/resolve/main/data.zip)ä¸‹è½½æ‰€æœ‰çš„è¯„æµ‹æ•°æ®ã€‚

#### æ•°æ®æ ¼å¼
**LongBench**ï¼ˆLongBench-Eï¼‰ä¸­æ‰€æœ‰æ•°æ®éƒ½ç»Ÿä¸€ä¸ºä»¥ä¸‹æ ¼å¼ï¼š
```json
{
    "input": "ä»»åŠ¡çš„è¾“å…¥/æŒ‡ä»¤ï¼Œé€šå¸¸è¾ƒçŸ­ï¼Œæ¯”å¦‚QAä¸­çš„é—®é¢˜ã€Few-shotä»»åŠ¡ä¸­çš„æé—®ç­‰",
    "context": "ä»»åŠ¡æ‰€éœ€çš„é•¿è¯­å¢ƒæ–‡æœ¬ï¼Œæ¯”å¦‚æ–‡æ¡£ã€è·¨æ–‡ä»¶ä»£ç ã€Few-shotä»»åŠ¡ä¸­çš„few-shotæ ·æœ¬",
    "answers": "ç”±æ‰€æœ‰æ ‡å‡†ç­”æ¡ˆç»„æˆçš„åˆ—è¡¨",
    "length": "å‰ä¸‰é¡¹æ–‡æœ¬çš„æ€»é•¿åº¦ï¼ˆä¸­ã€è‹±æ–‡åˆ†åˆ«ç”¨å­—ã€è¯æ•°ç»Ÿè®¡ï¼‰",
    "dataset": "æœ¬æ¡æ•°æ®æ‰€å±æ•°æ®é›†åç§°",
    "language": "æœ¬æ¡æ•°æ®çš„è¯­è¨€",
    "all_classes": "åˆ†ç±»ä»»åŠ¡ä¸­çš„æ‰€æœ‰ç±»åˆ«ï¼Œéåˆ†ç±»ä»»åŠ¡åˆ™ä¸ºnull",
    "_id": "æ¯æ¡æ•°æ®çš„éšæœºid"
}
```

#### è¯„æµ‹
é€šè¿‡pipå®‰è£…ä¾èµ–ï¼š`pip install -r requirements.txt`ã€‚å¯¹äºåŸºäºLlama-2çš„æ¨¡å‹ï¼Œæˆ‘ä»¬æ¨èä½¿ç”¨Flash Attentionè¿›è¡Œä¼˜åŒ–å¹¶èŠ‚çœæ˜¾å­˜ï¼Œå¯ä»¥æ ¹æ®[Flash Attention](https://github.com/Dao-AILab/flash-attention)çš„ä»£ç åº“æ¥å®‰è£…ç›¸å…³ä¾èµ–ã€‚

é¦–å…ˆï¼Œè¿è¡Œä»“åº“ä¸‹çš„[pred.py](pred.py)ï¼Œå¹¶é€šè¿‡`--model`é€‰æ‹©ä½ æƒ³è¯„æµ‹çš„æ¨¡å‹ï¼Œæˆ‘ä»¬ä»¥ChatGLM2-6B-32kæ¨¡å‹ä¸ºä¾‹ï¼ˆä»£ç å°†ä¼šæ ¹æ®[model2path.json](config/model2path.json)ä¸­çš„è·¯å¾„è‡ªåŠ¨ä¸‹è½½HuggingFaceæ¨¡å‹ï¼Œä½ å¯ä»¥ä¿®æ”¹æ­¤æ–‡ä»¶ä¸­çš„è·¯å¾„ä»¥ä»æœ¬åœ°è½½å…¥æ¨¡å‹å‚æ•°ï¼‰ï¼š
```bash
CUDA_VISIBLE_DEVICES=0 python pred.py --model chatglm2-6b-32k
```
å¯ä»¥åœ¨`pred/`å¯¹åº”æ¨¡å‹åç§°çš„æ–‡ä»¶å¤¹ä¸‹å¾—åˆ°æ¨¡å‹åœ¨LongBenchæ‰€æœ‰æ•°æ®é›†ä¸‹çš„è¾“å‡ºï¼Œç±»ä¼¼åœ°ï¼Œé€šè¿‡`--e`å‘½ä»¤ï¼š
```bash
CUDA_VISIBLE_DEVICES=0 python pred.py --model chatglm2-6b-32k --e
```
å¯ä»¥åœ¨`pred_e/`å¯¹åº”æ¨¡å‹åç§°çš„æ–‡ä»¶å¤¹ä¸‹å¾—åˆ°æ¨¡å‹åœ¨LongBench-Eæ‰€æœ‰æ•°æ®é›†ä¸‹çš„è¾“å‡ºã€‚æ­¤åè¿è¡Œ[eval.py](eval.py)çš„è¯„æµ‹ä»£ç ï¼š
```bash
python eval.py --model chatglm2-6b-32k
```
å¯ä»¥åœ¨å­˜å‚¨æ¨¡å‹è¾“å‡ºæ–‡ä»¶å¤¹ä¸‹çš„`result.json`ä¸­å¾—åˆ°æ¨¡å‹åœ¨LongBenchå„æ•°æ®é›†ä¸Šçš„è¯„æµ‹ç»“æœã€‚é€šè¿‡`--e`å‘½ä»¤ä¹Ÿå¯ä»¥å¾—åˆ°æ¨¡å‹åœ¨LongBench-Eæ‰€æœ‰æ•°æ®é›†ä¸­ä¸åŒé•¿åº¦åŒºé—´å†…çš„å¹³å‡å¾—åˆ†ã€‚

è¯·æ³¨æ„ï¼Œæˆ‘ä»¬åœ¨`config/`ä¸‹æä¾›äº†æˆ‘ä»¬æ€»ç»“å‡ºæ¥çš„åœ¨å„æ•°æ®é›†ä¸Šé€‚åˆçš„è¾“å…¥æ ¼å¼å’Œæœ€å¤§è¾“å‡ºé•¿åº¦é™åˆ¶ï¼Œåœ¨è¯„æµ‹çš„æ—¶å€™å¯ä»¥è¿›è¡Œä¿®æ”¹ä»¥æ›´å¥½åœ°é€‚ç”¨ä½ è¦è¯„æµ‹çš„æ¨¡å‹ï¼Œä¿®æ”¹ååœ¨[pred.py](pred.py)è¯„æµ‹æ—¶ä¼šè‡ªåŠ¨æŒ‰ç…§æ–°çš„æ ¼å¼å»æ•´ç†æ•°æ®å¹¶å¾—åˆ°å¯¹åº”çš„æ¨¡å‹è¾“å‡ºã€‚

æ­¤å¤–æˆ‘ä»¬è¿˜æä¾›äº†åŸºäºæ£€ç´¢å’Œåˆ†æ®µæ‘˜è¦çš„é•¿æ–‡æœ¬å‹ç¼©è¯„æµ‹ä»£ç ï¼ˆå®ç°æ–¹å¼å‚è€ƒLongBenchè®ºæ–‡ä¸­çš„4.2èŠ‚ï¼‰ï¼Œåˆ†åˆ«åœ¨`retrieval/`å’Œ`summ/`ä¸¤ä¸ªæ–‡ä»¶å¤¹ä¸‹ã€‚

<a name="è¯¦ç»†è¯„æµ‹ç»“æœ"></a>
## ğŸ“Š è¯¦ç»†è¯„æµ‹ç»“æœ
ä¸‹é¢çš„å‡ å¼ è¡¨æ ¼å±•ç¤ºäº†æ¨¡å‹åœ¨æ‰€æœ‰å­ä»»åŠ¡æ•°æ®é›†ä¸Šçš„Zero-shotè¯„æµ‹ç»“æœï¼ˆ%ï¼‰ï¼Œå…¶ä¸­çš„ä¸­æ–‡æ•°æ®é›†ä»¥â€œzhâ€æ ‡ç¤ºï¼ˆå„ä»»åŠ¡è¯„ä¼°æ‰€ç”¨æŒ‡æ ‡è¯·å‚è€ƒ[è¿™é‡Œ](task_zh.md)ï¼‰ã€‚

#### å•æ–‡æ¡£QA
|                   | NarrativeQA | Qasper | MultiFieldQA-en | MultiFieldQA-zh |
|-------------------|:-----------:|:------:|:---------------:|:---------------:|
| GPT-3.5-Turbo-16k | 23.6 | 43.3 | 52.3 | 61.2 |
| Llama2-7B-chat-4k | 18.7 | 19.2 | 36.8 | 11.9 |
| LongChat-v1.5-7B-32k | 16.9 | 27.7 | 41.4 | 29.1 |
| XGen-7B-8k | 18.0 | 18.1 | 37.7 | 14.8 |
| InternLM-7B-8k | 12.1 | 16.7 | 23.4 | 33.6 |
| ChatGLM2-6B | 11.8 | 22.5 | 35.0 | 33.2 |
| ChatGLM2-6B-32k | 21.1 | 31.5 | 46.2 | 51.6 |
| Vicuna-v1.5-7B-16k | 19.4 | 26.1 | 38.5 | 43.0 |

#### å¤šæ–‡æ¡£QA
|                      | HotpotQA | 2WikiMQA | Musique | DuReader (zh) |
|----------------------|:--------:|:--------:|:-------:|:--------:|
| GPT-3.5-Turbo-16k | 51.6 | 37.7 | 26.9 | 28.7 |
| Llama2-7B-chat-4k | 25.4 | 32.8 | 9.4 | 5.2 |
| LongChat-v1.5-7B-32k | 31.5 | 20.6 | 9.7 | 19.5 |
| XGen-7B-8k | 29.7 | 21.1 | 10.3 | 11.0 |
| InternLM-7B-8k | 28.7 | 22.8 | 9.0 | 11.1 |
| ChatGLM2-6B | 22.4 | 20.1 | 6.1 | 16.3 |
| ChatGLM2-6B-32k | 45.1 | 34.0 | 21.9 | 37.6 |
| Vicuna-v1.5-7B-16k | 25.3 | 20.8 | 9.8 | 19.3 |

#### æ‘˜è¦
|            | GovReport | QMSum | MultiNews | VCSUM (zh) |
|:-----------|:---------:|:-----:|:-----:|:-----:|
| GPT-3.5-Turbo-16k | 29.5 | 23.4 | 26.7 | 16.0 |
| Llama2-7B-chat-4k | 27.3 | 20.8 | 25.8 | 0.2 |
| LongChat-v1.5-7B-32k | 30.8 | 22.7 | 26.4 | 9.9 |
| XGen-7B-8k | 27.3 | 20.5 | 26.2 | 2.2 |
| InternLM-7B-8k | 9.7 | 15.9 | 22.8 | 12.4 |
| ChatGLM2-6B | 23.2 | 21.1 | 25.2 | 14.5 |
| ChatGLM2-6B-32k | 32.4 | 24.0 | 26.5 | 16.2 |
| Vicuna-v1.5-7B-16k | 27.9 | 22.8 | 27.2 | 15.1 |

#### Few-shotå­¦ä¹ 
|     | TREC | TriviaQA | SAMSum | LSHT (zh) |
| --- | :-: | :-: | :-: | :-: |
| GPT-3.5-Turbo-16k | 68.0 | 91.4 | 41.7 | 29.2 |
| Llama2-7B-chat-4k | 61.5 | 77.8 | 40.7 | 19.8 |
| LongChat-v1.5-7B-32k | 63.5 | 82.3 | 34.2 | 23.2 |
| XGen-7B-8k | 65.5 | 77.8 | 25.3 | 20.5 |
| InternLM-7B-8k | 52.0 | 77.8 | 21.2 | 15.2 |
| ChatGLM2-6B | 44.5 | 70.6 | 29.5 | 20.8 |
| ChatGLM2-6B-32k | 62.5 | 78.7 | 36.3 | 27.7 |
| Vicuna-v1.5-7B-16k | 71.5 | 86.2 | 40.8 | 28.8 |

#### åˆæˆä»»åŠ¡
|     | Passage Count | PassageRetrieval-en | PassageRetrieval-zh |
| --- | :-: | :-: | :-: |
| GPT-3.5-Turbo-16k | 4.5 | 71.0 | 77.5 |
| Llama2-7B-chat-4k | 2.1 | 9.8 | 0.5 |
| LongChat-v1.5-7B-32k | 1.0 | 30.5 | 7.6 |
| XGen-7B-8k | 2.1 | 8.5 | 3.5 |
| InternLM-7B-8k | 3.0 | 6.0 | 0.9 |
| ChatGLM2-6B | 2.5 | 3.0 | 6.5 |
| ChatGLM2-6B-32k | 1.5 | 77.0 | 64.5 |
| Vicuna-v1.5-7B-16k | 6.5 | 4.5 | 5.0 |

#### ä»£ç è¡¥å…¨
|     | LCC | RepoBench-P |
| --- | :-: | :-: |
| GPT-3.5-Turbo-16k | 54.7 | 53.6 |
| Llama2-7B-chat-4k | 52.4 | 43.8 |
| LongChat-v1.5-7B-32k | 53.0 | 55.3 |
| XGen-7B-8k | 38.6 | 38.6 |
| InternLM-7B-8k | 44.1 | 28.8 |
| ChatGLM2-6B | 49.0 | 43.2 |
| ChatGLM2-6B-32k | 55.6 | 49.9 |
| Vicuna-v1.5-7B-16k | 51.0 | 43.5 |

<a name="è‡´è°¢"></a>
## ğŸ“„ è‡´è°¢
- LongBenchçš„éƒ¨åˆ†ä»»åŠ¡åŸºäºä¹‹å‰çš„ç ”ç©¶è€…æå‡ºçš„æ•°æ®é›†æ„å»ºï¼ŒåŒ…æ‹¬[HotpotQA](https://hotpotqa.github.io/)ï¼Œ[2WikiMultihopQA](https://aclanthology.org/2020.coling-main.580/)ï¼Œ[MuSiQue](https://arxiv.org/abs/2108.00573)ï¼Œ[DuReader](https://github.com/baidu/DuReader)ï¼Œ[NarrativeQA](https://arxiv.org/pdf/1712.07040.pdf)ï¼Œ[Qasper](https://arxiv.org/pdf/2105.03011.pdf)ï¼Œ[GovReport](https://arxiv.org/pdf/2104.02112.pdf)ï¼Œ[QMSum](https://arxiv.org/pdf/2104.05938.pdf)ï¼Œ[MultiNews](https://aclanthology.org/P19-1102.pdf)ï¼Œ[VCSUM](https://arxiv.org/abs/2305.05280)ï¼Œ[TriviaQA](https://nlp.cs.washington.edu/triviaqa/)ï¼Œ[TREC](https://aclanthology.org/C02-1150.pdf)ï¼Œ[SAMSum](https://aclanthology.org/D19-5409.pdf)ï¼Œ[LSHT](http://tcci.ccf.org.cn/conference/2014/dldoc/evatask6.pdf)ï¼Œ[LCC](https://arxiv.org/abs/2306.14893)å’Œ[RepoBench-P](https://arxiv.org/abs/2306.03091)ã€‚

<a name="å¼•ç”¨"></a>
## ğŸ“ å¼•ç”¨
```
@misc{bai2023longbench,
      title={LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding}, 
      author={Yushi Bai and Xin Lv and Jiajie Zhang and Hongchang Lyu and Jiankai Tang and Zhidian Huang and Zhengxiao Du and Xiao Liu and Aohan Zeng and Lei Hou and Yuxiao Dong and Jie Tang and Juanzi Li},
      year={2023},
      eprint={2308.14508},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```
å¦‚æœæ‚¨ä½¿ç”¨Longbenchï¼Œè¯·è€ƒè™‘å¼•ç”¨LongBenchæ‰€åŸºäºçš„æ•°æ®é›†å¯¹åº”çš„è®ºæ–‡ï¼Œç›¸å…³å¼•ç”¨ä¿¡æ¯åœ¨[è¿™é‡Œ](refs/ref.bib)ã€‚
